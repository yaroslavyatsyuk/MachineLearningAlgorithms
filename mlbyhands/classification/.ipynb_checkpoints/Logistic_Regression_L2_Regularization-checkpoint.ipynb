{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION WITH L2 REGULARIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Algorithm`\n",
    "## `Goal to maximize log likelihood function`\n",
    "\n",
    "### `Log Likelihood simplified form:`\n",
    "### $$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (y^{(i)} - 1)\\mathbf{w}^T \\mathbf{x}^{(i)} - \\ln\\left(1 + \\exp(-\\mathbf{w}^T \\mathbf{x}^{(i)}\\right) \\Big)\\color{red}{-\\lambda\\|\\mathbf{w}\\|_2^2} $$\n",
    "$$P(\\mathbf{x}^{(i)}, \\mathbf{w}) = \\frac{\\mbox 1}{\\mbox 1 + e^{-\\mathbf{w}^T\\mathbf{x}^{(i)}}}$$\n",
    "<br></br>\n",
    "### `Gradient Ascent step:`\n",
    "### $$ \\mathbf{w}^{new} = \\mathbf{w}^{old} + \\lambda \\mathbf{X}^T(y^{(i)} - P(\\mathbf{X},\\mathbf{w})) \\color{red}{-2\\lambda \\mathbf{w} } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, l2=0.01, step_size=1e-6, n_rounds=150):\n",
    "        self.l2 = l2\n",
    "        self.step_size = step_size\n",
    "        self.n_rounds = n_rounds\n",
    "        \n",
    "    def cost_function_with_l2(self, X, y, l2_penalty, coefficients):\n",
    "        scores = X @ coefficients\n",
    "        logexp = np.log(1.0 + np.exp(-scores))\n",
    "\n",
    "        # Simple check to prevent overflow\n",
    "        mask = np.isinf(logexp)\n",
    "        logexp[mask] = -scores[mask]\n",
    "\n",
    "        return np.sum((y-1)*scores - logexp) - l2_penalty*np.sum(coefficients[1:]**2)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X @ self.weights\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        weights = np.zeros(X.shape[1])\n",
    "        cost_history = list()\n",
    "        for itr in range(self.n_rounds):\n",
    "            penalty = (2 * self.l2 * weights)\n",
    "            penalty[0] = 0\n",
    "            \n",
    "            errors = y - self._sigmoid(X, weights)\n",
    "            weights = weights + self.step_size * ((X.T @ errors) - penalty)\n",
    "            \n",
    "            logloss = self.cost_function_with_l2(X, y, self.l2, weights)\n",
    "            cost_history.append(logloss)\n",
    "        \n",
    "        self.weights = weights\n",
    "        return (weights, cost_history)\n",
    "\n",
    "    def _sigmoid(self, X, w):\n",
    "        return 1/(1 + np.exp(-X @ w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict product review sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"../data/amazon_baby_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...       5          1  \n",
       "1  We wanted to get something to keep track of ou...       5          1  \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1  \n",
       "3  One of baby's first and favorite books, and it...       4          1  \n",
       "4  Very cute interactive book! My son loves this ...       5          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of positive reviews = 26579\n",
      "# of negative reviews = 26493\n"
     ]
    }
   ],
   "source": [
    "products[\"sentiment\"] = products[\"sentiment\"].apply(lambda x: x if x==1 else 0)\n",
    "print('# of positive reviews =', len(products[products['sentiment']==1]))\n",
    "print('# of negative reviews =', len(products[products['sentiment']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"review\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "products[\"review\"] = products[\"review\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply text cleaning on the review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/important_words.json', 'r') as f: # Reads the list of most frequent words\n",
    "    important_words = json.load(f)\n",
    "important_words = [str(s) for s in important_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "def remove_punctuation(text):\n",
    "    translator = text.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    return text\n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate words frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = products.sample(frac=0.7, random_state=12) \n",
    "test = products.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(df, features, label):\n",
    "    df['intercept'] = 1\n",
    "    features = ['intercept'] + features\n",
    "    features_df = df[features]\n",
    "    return(np.array(features_df), np.array(df[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_numpy_data(train, important_words, 'sentiment') \n",
    "X_test, y_test = get_numpy_data(test, important_words, 'sentiment') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore effects of L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with L2 = 0\n",
    "log_reg_l2_0 = LogisticRegression(l2=0, step_size=5e-6, n_rounds=300)\n",
    "coefficients_0_penalty, cost_history_0_penalty  = log_reg_l2_0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with L2 = 4\n",
    "log_reg_l2_4 = LogisticRegression(l2=4, step_size=5e-6, n_rounds=300)\n",
    "coefficients_4_penalty, cost_history_4_penalty  = log_reg_l2_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with L2 = 10\n",
    "log_reg_l2_10 = LogisticRegression(l2=10, step_size=5e-6, n_rounds=300)\n",
    "coefficients_10_penalty, cost_history_10_penalty= log_reg_l2_10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with L2 = 1e2\n",
    "log_reg_l2_1e2 = LogisticRegression(l2=1e2, step_size=5e-6, n_rounds=300)\n",
    "coefficients_1e2_penalty, cost_history_1e2_penalty  = log_reg_l2_1e2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with L2 = 1e3\n",
    "log_reg_l2_1e3 = LogisticRegression(l2=1e3, step_size=5e-6, n_rounds=300)\n",
    "coefficients_1e3_penalty, cost_history_1e3_penalty  = log_reg_l2_1e3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with L2 = 1e5\n",
    "log_reg_l2_1e5 = LogisticRegression(l2=1e5, step_size=5e-6, n_rounds=300)\n",
    "coefficients_1e5_penalty, cost_history_1e5_penalty  = log_reg_l2_1e5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame({'word': ['(intercept)'] + important_words})\n",
    "def add_coefficients_to_table(coefficients, column_name):\n",
    "    table[column_name] = coefficients\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_coefficients_to_table(coefficients_0_penalty, 'coefficients [L2=0]')\n",
    "add_coefficients_to_table(coefficients_4_penalty, 'coefficients [L2=4]')\n",
    "add_coefficients_to_table(coefficients_10_penalty, 'coefficients [L2=10]')\n",
    "add_coefficients_to_table(coefficients_1e2_penalty, 'coefficients [L2=1e2]')\n",
    "add_coefficients_to_table(coefficients_1e3_penalty, 'coefficients [L2=1e3]')\n",
    "add_coefficients_to_table(coefficients_1e5_penalty, 'coefficients [L2=1e5]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top 5 positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = table[[\"word\", \"coefficients [L2=0]\"]].sort_values(by=\"coefficients [L2=0]\", ascending=False)[\"word\"][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = table[[\"word\", \"coefficients [L2=0]\"]].sort_values(by=\"coefficients [L2=0]\")[\"word\"][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualize coefficiets path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "def make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list):\n",
    "    positive_words = np.array(positive_words)\n",
    "    negative_words = np.array(negative_words)\n",
    "    cmap_positive = plt.get_cmap('Reds')\n",
    "    cmap_negative = plt.get_cmap('Blues')\n",
    "    \n",
    "    xx = l2_penalty_list\n",
    "    plt.plot(xx, [0.]*len(xx), '--', lw=1, color='k')\n",
    "    \n",
    "    table_positive_words = table[table.word.isin(positive_words)]\n",
    "    table_negative_words = table[table.word.isin(negative_words)]\n",
    "    del table_positive_words['word']\n",
    "    del table_negative_words['word']\n",
    "    \n",
    "    for i in range(len(positive_words)):\n",
    "        color = cmap_positive(0.8*((i+1)/(len(positive_words)*1.2)+0.15))\n",
    "        plt.plot(xx, np.array(table_positive_words[i:i+1]).flatten(), '-', \n",
    "                 label=positive_words[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    for i in range(len(negative_words)):\n",
    "        color = cmap_negative(0.8*((i+1)/(len(negative_words)*1.2)+0.15))\n",
    "        plt.plot(xx, np.array(table_negative_words[i:i+1]).flatten(),\n",
    "                 '-', label=negative_words[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    plt.legend(loc='best', ncol=3, prop={'size':16}, columnspacing=0.5)\n",
    "    plt.axis([1, 1e5, -1, 2])\n",
    "    plt.title('Coefficient path')\n",
    "    plt.xlabel('L2 penalty ($\\lambda$)')\n",
    "    plt.ylabel('Coefficient value')\n",
    "    plt.xscale('log')\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list=[0, 4, 10, 1e2, 1e3, 1e5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified data points}}{\\mbox{# total data points}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_accuracy(X, y, coefficients):\n",
    "    scores = X @ coefficients\n",
    "    apply_threshold = np.vectorize(lambda x: 1 if x > 0  else 0)\n",
    "    predictions = apply_threshold(scores)\n",
    "    \n",
    "    num_correct = (predictions == y).sum()\n",
    "    accuracy = num_correct / len(X)    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = {}\n",
    "train_accuracy[0]   = get_classification_accuracy(X_train, y_train, coefficients_0_penalty)\n",
    "train_accuracy[4]   = get_classification_accuracy(X_train, y_train, coefficients_4_penalty)\n",
    "train_accuracy[10]  = get_classification_accuracy(X_train, y_train, coefficients_10_penalty)\n",
    "train_accuracy[1e2] = get_classification_accuracy(X_train, y_train, coefficients_1e2_penalty)\n",
    "train_accuracy[1e3] = get_classification_accuracy(X_train, y_train, coefficients_1e3_penalty)\n",
    "train_accuracy[1e5] = get_classification_accuracy(X_train, y_train, coefficients_1e5_penalty)\n",
    "\n",
    "test_accuracy = {}\n",
    "test_accuracy[0]   = get_classification_accuracy(X_test, y_test, coefficients_0_penalty)\n",
    "test_accuracy[4]   = get_classification_accuracy(X_test, y_test, coefficients_4_penalty)\n",
    "test_accuracy[10]  = get_classification_accuracy(X_test, y_test, coefficients_10_penalty)\n",
    "test_accuracy[1e2] = get_classification_accuracy(X_test, y_test, coefficients_1e2_penalty)\n",
    "test_accuracy[1e3] = get_classification_accuracy(X_test, y_test, coefficients_1e3_penalty)\n",
    "test_accuracy[1e5] = get_classification_accuracy(X_test, y_test, coefficients_1e5_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple report\n",
    "for key in sorted(test_accuracy.keys()):\n",
    "    print(\"L2 penalty = %g\" % key)\n",
    "    print(\"train accuracy = %s, test_accuracy = %s\" % (train_accuracy[key], test_accuracy[key]))\n",
    "    print(\"--------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "\n",
    "sorted_list = sorted(train_accuracy.items(), key=lambda x:x[0])\n",
    "plt.plot([p[0] for p in sorted_list], [p[1] for p in sorted_list], '-', linewidth=4, label='Training accuracy')\n",
    "sorted_list = sorted(test_accuracy.items(), key=lambda x:x[0])\n",
    "plt.plot([p[0] for p in sorted_list], [p[1] for p in sorted_list], '-', linewidth=4, label='Test accuracy')\n",
    "plt.xscale('symlog')\n",
    "plt.axis([0, 1e3, 0.78, 0.786])\n",
    "plt.legend(loc='lower left')\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
