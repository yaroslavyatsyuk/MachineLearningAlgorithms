{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression\n",
    "## Implementations:\n",
    "- ### `Newton Method`\n",
    "- ### `Matrix Equation`\n",
    "- ### `Gradient Descent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    ALGORITHMS = ['newton', 'matrix_equation', 'gradient_descent']\n",
    "    CONVERGENCE_THRESHOLD = 1.5e-8\n",
    "\n",
    "    \"\"\"\n",
    "    n_iterations: float\n",
    "        The number of iteration witch algorithm will perform for tuning weights, \n",
    "        this attribute works only for gradient_descent solver\n",
    "    learning_rate: float\n",
    "        The gradient decent step size, this attribute works only for gradient_descent solver\n",
    "    solver: string\n",
    "        The algorithm that will be used for training linear regression, list of available\n",
    "        algorithms: ['newton', \"matrix_equation\", \"gradient_descent\"] \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate=1.5e-11, n_iterations=1000, solver='newton'):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.cost_history = list()\n",
    "\n",
    "        if solver in (LinearRegression.ALGORITHMS):\n",
    "            self.solver = solver\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for 'solver' attribute: %s, 'solver' \"\n",
    "                             \"should be in ['newton, 'matrix_equation', 'gradient_descent']\" % solver)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.weights = np.zeros(X.shape[1] + 1)\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # Add intercept as first column\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "        if self.solver == \"matrix_equation\":\n",
    "            self.weights = self._solve_matrix_equation(X, y)\n",
    "\n",
    "        elif self.solver == \"newton\":\n",
    "            self.weights = self._solve_newton(X, y, self.weights)\n",
    "\n",
    "        elif self.solver == \"gradient_descent\":\n",
    "            self.weights = self._solve_gradient_descent(X, y, self.weights, self.learning_rate, self.n_iterations)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown algorithm name\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.insert(np.array(X), 0, 1, axis=1)\n",
    "        return X @ self.weights\n",
    "    \n",
    "    def _calculate_MSE(self, X, y, w, add_intercept=False):\n",
    "        if add_intercept:\n",
    "            X = np.insert(np.array(X), 0, 1, axis=1)\n",
    "\n",
    "        MSE = np.mean((y - X @ w) ** 2)\n",
    "        return MSE\n",
    "\n",
    "    def _solve_matrix_equation(self, X, y):\n",
    "        '''\n",
    "             Classic formula for solving RSS (Residual Sum of Squares)\n",
    "             RSS(w) = (y - X @ w).T @(y - X @ w)\n",
    "        '''\n",
    "        return np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "\n",
    "    def _solve_newton(self, X, y, weights):\n",
    "        w = weights\n",
    "        cost_residual = float(\"inf\")\n",
    "\n",
    "        while (cost_residual > LinearRegression.CONVERGENCE_THRESHOLD):\n",
    "            prev_cost = self._calculate_MSE(X, y, w)\n",
    "            w = w - np.linalg.inv(self._hessian(X)) @ self._gradient(X, y, w)\n",
    "            new_cost = self._calculate_MSE(X, y, w)\n",
    "\n",
    "            cost_residual = abs(prev_cost - new_cost)\n",
    "\n",
    "        return w\n",
    "\n",
    "    def _solve_gradient_descent(self, X, y, weights, learning_rate=1.5e-11, n_iterations=1000):\n",
    "        w = weights\n",
    "        self.cost_history.append(self._calculate_MSE(X, y, w))\n",
    "        for _ in range(n_iterations):\n",
    "            w = w - learning_rate * self._gradient(X, y, w)\n",
    "            self.cost_history.append(self._calculate_MSE(X, y, w))\n",
    "\n",
    "        return w\n",
    "\n",
    "    def _gradient(self, X, y, weights):\n",
    "        '''Gradient vector from RSS'''\n",
    "        m = len(X)\n",
    "        return -2 * X.T @ (y - X @ weights)\n",
    "\n",
    "    def _hessian(self, X):\n",
    "        '''Hessian matrix from RSS'''\n",
    "        m = len(X)\n",
    "        return 2 * X.T @ X\n",
    "    \n",
    "    def get_coefficients(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def get_training_history(self):\n",
    "        return self.cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Test implementation on sklearn `california_housing` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression as SKLearnLinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 4128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Train custom model and compare with sklearn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train linear legression with Matrix Equation solever (custom model)\n",
    "custom_lin_reg = LinearRegression(solver=\"matrix_equation\")\n",
    "custom_lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train linear regression sklearn model\n",
    "sklearn_lin_reg = SKLearnLinearRegression()\n",
    "sklearn_lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_custom = custom_lin_reg.predict(X_test)\n",
    "y_pred_sklearn = sklearn_lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom model MSE: 0.5289841670593455\n",
      "SKLearn model MSE: 0.5289841670367221\n"
     ]
    }
   ],
   "source": [
    "print(\"Custom model MSE:\", mean_squared_error(y_test, y_pred_custom))\n",
    "print(\"SKLearn model MSE:\", mean_squared_error(y_test, y_pred_sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom model coefficients: [-3.68585687e+01  4.33333407e-01  9.29324344e-03 -9.86433746e-02\n",
      "  5.93215489e-01 -7.56192490e-06 -4.74516385e-03 -4.21449332e-01\n",
      " -4.34166037e-01]\n",
      "SKLearn model coefficients: -36.85856910680125 [ 4.33333407e-01  9.29324337e-03 -9.86433739e-02  5.93215487e-01\n",
      " -7.56192502e-06 -4.74516383e-03 -4.21449336e-01 -4.34166041e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"Custom model coefficients:\", custom_lin_reg.get_coefficients())\n",
    "print(\"SKLearn model coefficients:\", sklearn_lin_reg.intercept_, sklearn_lin_reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check MSE for Newton Method implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train linear legression with Newton Medhod solver (custom model)\n",
    "custom_lin_reg_newton = LinearRegression(solver=\"newton\")\n",
    "custom_lin_reg_newton.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_custom_newton = custom_lin_reg_newton.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom model Newton Method MSE: 0.5289841670367209\n",
      "SKLearn model MSE: 0.5289841670367221\n"
     ]
    }
   ],
   "source": [
    "print(\"Custom model Newton Method MSE:\", mean_squared_error(y_test, y_pred_custom_newton))\n",
    "print(\"SKLearn model MSE:\", mean_squared_error(y_test, y_pred_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last but not least simple gradient descent approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train linear legression with Newton Medhod solver (custom model)\n",
    "custom_lin_reg_grad_desc = LinearRegression(solver=\"gradient_descent\", learning_rate = 1.7e-11, n_iterations=1000)\n",
    "custom_lin_reg_grad_desc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_custom_grad_desc = custom_lin_reg_grad_desc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom model Gradient Descent MSE: 1.2915521855179877\n",
      "SKLearn model MSE: 0.5289841670367221\n"
     ]
    }
   ],
   "source": [
    "print(\"Custom model Gradient Descent MSE:\", mean_squared_error(y_test, y_pred_custom_grad_desc))\n",
    "print(\"SKLearn model MSE:\", mean_squared_error(y_test, y_pred_sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Check that the MSE decreases at each iteration\n",
    "plt.plot(custom_lin_reg_grad_desc.get_training_history())\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Iterations');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}