{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION WITH L2 REGULARIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Algorithm`\n",
    "## `Goal to maximize log likelihood function`\n",
    "\n",
    "### `Log Likelihood simplifyed form:`\n",
    "### $$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (y^{(i)} - 1)\\mathbf{w}^T \\mathbf{x}^{(i)} - \\ln\\left(1 + \\exp(-\\mathbf{w}^T \\mathbf{x}^{(i)}\\right) \\Big)\\color{red}{-\\lambda\\|\\mathbf{w}\\|_2^2} $$\n",
    "$$P(\\mathbf{x}^{(i)}, \\mathbf{w}) = \\frac{\\mbox 1}{\\mbox 1 + e^{-\\mathbf{w}^T\\mathbf{x}^{(i)}}}$$\n",
    "<br></br>\n",
    "### `Gradient Ascent step:`\n",
    "### $$ \\mathbf{w}^{new} = \\mathbf{w}^{old} + \\lambda \\mathbf{X}^T(y^{(i)} - P(\\mathbf{X},\\mathbf{w})) \\color{red}{-2\\lambda \\mathbf{w} } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, l2=0.01, step_size=1e-6, n_rounds=150):\n",
    "        self.l2 = l2\n",
    "        self.step_size = step_size\n",
    "        self.n_rounds = n_rounds\n",
    "        \n",
    "    def cost_function_with_l2(self, X, y, l2_penalty, coefficients):\n",
    "        scores = X @ coefficients\n",
    "        logexp = np.log(1. + np.exp(-scores))\n",
    "\n",
    "        # Simple check to prevent overflow\n",
    "        mask = np.isinf(logexp)\n",
    "        logexp[mask] = -scores[mask]\n",
    "\n",
    "        return np.sum((y-1)*scores - logexp) - l2_penalty*np.sum(coefficients[1:]**2)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X @ self.weights\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        weights = np.zeros(X.shape[1])\n",
    "        cost_history = list()\n",
    "        for itr in range(self.n_rounds):\n",
    "            penalty = (2 * self.l2 * weights)\n",
    "            penalty[0] = 0\n",
    "            \n",
    "            errors = y - self.__sigmoid(X, weights)\n",
    "            weights = weights + self.step_size * ((X.T @ errors) - penalty)\n",
    "            \n",
    "            logloss = self.cost_function_with_l2(X, y, self.l2, weights)\n",
    "            cost_history.append(logloss)\n",
    "        \n",
    "        self.weights = weights\n",
    "        return (weights, cost_history)\n",
    "\n",
    "    def __sigmoid(self, X, w):\n",
    "        return 1/(1 + np.exp(-X @ w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict product review sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"./data/amazon_baby_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...       5          1  \n",
       "1  We wanted to get something to keep track of ou...       5          1  \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1  \n",
       "3  One of baby's first and favorite books, and it...       4          1  \n",
       "4  Very cute interactive book! My son loves this ...       5          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of positive reviews = 26579\n",
      "# of negative reviews = 26493\n"
     ]
    }
   ],
   "source": [
    "products[\"sentiment\"] = products[\"sentiment\"].apply(lambda x: x if x==1 else 0)\n",
    "print('# of positive reviews =', len(products[products['sentiment']==1]))\n",
    "print('# of negative reviews =', len(products[products['sentiment']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"review\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "products[\"review\"] = products[\"review\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply text cleaning on the review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/important_words.json', 'r') as f: # Reads the list of most frequent words\n",
    "    important_words = json.load(f)\n",
    "important_words = [str(s) for s in important_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "def remove_punctuation(text):\n",
    "    translator = text.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    return text\n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate words frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = products.sample(frac=0.8, random_state=0) \n",
    "test = products.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(df, features, label):\n",
    "    df['intercept'] = 1\n",
    "    features = ['intercept'] + features\n",
    "    features_df = df[features]\n",
    "    return(np.array(features_df), np.array(df[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_numpy_data(train, important_words, 'sentiment') \n",
    "X_test, y_test = get_numpy_data(test, important_words, 'sentiment') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore effects of L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with L2 = 0\n",
    "log_reg_l2_0 = LogisticRegression(l2=0, step_size=5e-6, n_rounds=300)\n",
    "coefficients_0_penalty, cost_history_0_penalty  = log_reg_l2_0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-29245.050518621658,\n",
       " -29068.355734868815,\n",
       " -28898.633641431283,\n",
       " -28735.22214805927,\n",
       " -28577.622420128424,\n",
       " -28425.439032714818,\n",
       " -28278.343956878092,\n",
       " -28136.054729950574,\n",
       " -27998.321079891037,\n",
       " -27864.9166134508,\n",
       " -27735.63355360325,\n",
       " -27610.279321653932,\n",
       " -27488.674240599634,\n",
       " -27370.649924577014,\n",
       " -27256.048092730663,\n",
       " -27144.71965027494,\n",
       " -27036.523942251515,\n",
       " -26931.328123025127,\n",
       " -26829.006606949817,\n",
       " -26729.440578958292,\n",
       " -26632.517551744397,\n",
       " -26538.130960921586,\n",
       " -26446.179792358078,\n",
       " -26356.56823759004,\n",
       " -26269.20537425588,\n",
       " -26184.00486914862,\n",
       " -26100.884701907653,\n",
       " -26019.76690765924,\n",
       " -25940.577337121293,\n",
       " -25863.24543284433,\n",
       " -25787.704020385332,\n",
       " -25713.889113315512,\n",
       " -25641.739731053916,\n",
       " -25571.197728598454,\n",
       " -25502.2076372987,\n",
       " -25434.716515880624,\n",
       " -25368.673810993612,\n",
       " -25304.031226605846,\n",
       " -25240.742601625167,\n",
       " -25178.763795169452,\n",
       " -25118.05257895434,\n",
       " -25058.568536305756,\n",
       " -25000.27296734186,\n",
       " -24943.128799902974,\n",
       " -24887.100505839302,\n",
       " -24832.154022295257,\n",
       " -24778.256677655747,\n",
       " -24725.377121844314,\n",
       " -24673.48526068559,\n",
       " -24622.5521940655,\n",
       " -24572.55015764171,\n",
       " -24523.452467874584,\n",
       " -24475.23347016542,\n",
       " -24427.868489903587,\n",
       " -24381.333786238327,\n",
       " -24335.606508403835,\n",
       " -24290.664654438035,\n",
       " -24246.48703214662,\n",
       " -24203.053222173952,\n",
       " -24160.34354305211,\n",
       " -24118.339018107647,\n",
       " -24077.021344114284,\n",
       " -24036.37286158671,\n",
       " -23996.376526618013,\n",
       " -23957.01588416941,\n",
       " -23918.275042727204,\n",
       " -23880.138650247165,\n",
       " -23842.591871311924,\n",
       " -23805.620365431645,\n",
       " -23769.210266422655,\n",
       " -23733.34816280302,\n",
       " -23698.021079147715,\n",
       " -23663.21645834982,\n",
       " -23628.922144737295,\n",
       " -23595.12636799822,\n",
       " -23561.817727870228,\n",
       " -23528.985179552426,\n",
       " -23496.618019800815,\n",
       " -23464.705873670497,\n",
       " -23433.238681870174,\n",
       " -23402.206688696446,\n",
       " -23371.600430517472,\n",
       " -23341.41072477715,\n",
       " -23311.62865949291,\n",
       " -23282.24558322154,\n",
       " -23253.25309546911,\n",
       " -23224.643037522397,\n",
       " -23196.407483680352,\n",
       " -23168.538732865716,\n",
       " -23141.029300597605,\n",
       " -23113.871911307207,\n",
       " -23087.059490979813,\n",
       " -23060.585160106933,\n",
       " -23034.442226933686,\n",
       " -23008.624180986928,\n",
       " -22983.124686870884,\n",
       " -22957.937578317295,\n",
       " -22933.05685247806,\n",
       " -22908.47666444913,\n",
       " -22884.19132201446,\n",
       " -22860.195280600135,\n",
       " -22836.483138428688,\n",
       " -22813.049631864586,\n",
       " -22789.88963094197,\n",
       " -22766.998135066566,\n",
       " -22744.370268883773,\n",
       " -22722.001278305474,\n",
       " -22699.886526688602,\n",
       " -22678.021491158615,\n",
       " -22656.401759071578,\n",
       " -22635.023024608723,\n",
       " -22613.881085497796,\n",
       " -22592.971839855632,\n",
       " -22572.291283146806,\n",
       " -22551.835505253348,\n",
       " -22531.60068765086,\n",
       " -22511.583100686465,\n",
       " -22491.779100954423,\n",
       " -22472.185128765184,\n",
       " -22452.79770570419,\n",
       " -22433.61343227653,\n",
       " -22414.62898563407,\n",
       " -22395.84111738165,\n",
       " -22377.246651459085,\n",
       " -22358.842482096028,\n",
       " -22340.62557183665,\n",
       " -22322.592949631475,\n",
       " -22304.741708993588,\n",
       " -22287.069006216803,\n",
       " -22269.57205865324,\n",
       " -22252.248143048095,\n",
       " -22235.094593929356,\n",
       " -22218.108802050298,\n",
       " -22201.288212882806,\n",
       " -22184.630325159564,\n",
       " -22168.13268946323,\n",
       " -22151.792906860865,\n",
       " -22135.60862758191,\n",
       " -22119.577549738053,\n",
       " -22103.697418083484,\n",
       " -22087.966022814035,\n",
       " -22072.381198403724,\n",
       " -22056.940822477416,\n",
       " -22041.64281471827,\n",
       " -22026.485135808645,\n",
       " -22011.465786403387,\n",
       " -21996.5828061342,\n",
       " -21981.83427264417,\n",
       " -21967.21830065117,\n",
       " -21952.733041039264,\n",
       " -21938.37667997719,\n",
       " -21924.147438062748,\n",
       " -21910.043569492445,\n",
       " -21896.063361255387,\n",
       " -21882.205132350584,\n",
       " -21868.467233027008,\n",
       " -21854.848044045393,\n",
       " -21841.34597596129,\n",
       " -21827.9594684285,\n",
       " -21814.686989522274,\n",
       " -21801.52703508158,\n",
       " -21788.47812806989,\n",
       " -21775.53881795374,\n",
       " -21762.707680098603,\n",
       " -21749.983315181482,\n",
       " -21737.364348619612,\n",
       " -21724.84943001485,\n",
       " -21712.43723261319,\n",
       " -21700.126452778903,\n",
       " -21687.91580948291,\n",
       " -21675.80404380485,\n",
       " -21663.789918448478,\n",
       " -21651.87221726995,\n",
       " -21640.049744818567,\n",
       " -21628.321325889647,\n",
       " -21616.685805089095,\n",
       " -21605.142046409353,\n",
       " -21593.68893281635,\n",
       " -21582.325365847108,\n",
       " -21571.050265217775,\n",
       " -21559.862568441586,\n",
       " -21548.76123045666,\n",
       " -21537.7452232632,\n",
       " -21526.81353556985,\n",
       " -21515.96517244896,\n",
       " -21505.19915500047,\n",
       " -21494.514520024175,\n",
       " -21483.91031970014,\n",
       " -21473.385621276935,\n",
       " -21462.93950676766,\n",
       " -21452.571072653263,\n",
       " -21442.27942959321,\n",
       " -21432.06370214311,\n",
       " -21421.923028479177,\n",
       " -21411.856560129323,\n",
       " -21401.863461710684,\n",
       " -21391.942910673417,\n",
       " -21382.094097050558,\n",
       " -21372.31622321382,\n",
       " -21362.608503635107,\n",
       " -21352.97016465366,\n",
       " -21343.4004442486,\n",
       " -21333.898591816767,\n",
       " -21324.463867955725,\n",
       " -21315.09554425174,\n",
       " -21305.792903072626,\n",
       " -21296.55523736536,\n",
       " -21287.381850458252,\n",
       " -21278.272055867645,\n",
       " -21269.22517710897,\n",
       " -21260.240547512,\n",
       " -21251.317510040353,\n",
       " -21242.45541711488,\n",
       " -21233.653630441102,\n",
       " -21224.911520840382,\n",
       " -21216.228468084868,\n",
       " -21207.60386073602,\n",
       " -21199.037095986703,\n",
       " -21190.527579506717,\n",
       " -21182.07472529161,\n",
       " -21173.677955514882,\n",
       " -21165.336700383254,\n",
       " -21157.05039799511,\n",
       " -21148.81849420194,\n",
       " -21140.640442472708,\n",
       " -21132.51570376116,\n",
       " -21124.443746375873,\n",
       " -21116.424045853037,\n",
       " -21108.456084831952,\n",
       " -21100.5393529331,\n",
       " -21092.673346638734,\n",
       " -21084.85756917595,\n",
       " -21077.091530402206,\n",
       " -21069.37474669315,\n",
       " -21061.706740832775,\n",
       " -21054.087041905812,\n",
       " -21046.51518519229,\n",
       " -21038.990712064282,\n",
       " -21031.513169884685,\n",
       " -21024.08211190806,\n",
       " -21016.697097183467,\n",
       " -21009.35769045923,\n",
       " -21002.063462089583,\n",
       " -20994.81398794323,\n",
       " -20987.6088493136,\n",
       " -20980.447632831023,\n",
       " -20973.329930376454,\n",
       " -20966.255338997038,\n",
       " -20959.223460823232,\n",
       " -20952.23390298757,\n",
       " -20945.286277544976,\n",
       " -20938.38020139466,\n",
       " -20931.515296203448,\n",
       " -20924.691188330653,\n",
       " -20917.907508754317,\n",
       " -20911.16389299889,\n",
       " -20904.459981064298,\n",
       " -20897.79541735629,\n",
       " -20891.16985061817,\n",
       " -20884.58293386375,\n",
       " -20878.034324311586,\n",
       " -20871.523683320444,\n",
       " -20865.050676325962,\n",
       " -20858.61497277846,\n",
       " -20852.216246081938,\n",
       " -20845.854173534168,\n",
       " -20839.528436267894,\n",
       " -20833.238719193097,\n",
       " -20826.98471094035,\n",
       " -20820.766103805137,\n",
       " -20814.58259369324,\n",
       " -20808.433880067085,\n",
       " -20802.319665893036,\n",
       " -20796.239657589686,\n",
       " -20790.193564977002,\n",
       " -20784.18110122644,\n",
       " -20778.201982811916,\n",
       " -20772.255929461644,\n",
       " -20766.342664110816,\n",
       " -20760.461912855142,\n",
       " -20754.613404905194,\n",
       " -20748.796872541538,\n",
       " -20743.01205107063,\n",
       " -20737.25867878154,\n",
       " -20731.53649690337,\n",
       " -20725.845249563412,\n",
       " -20720.18468374606,\n",
       " -20714.5545492524,\n",
       " -20708.95459866049,\n",
       " -20703.384587286328,\n",
       " -20697.844273145496,\n",
       " -20692.33341691541,\n",
       " -20686.851781898273,\n",
       " -20681.39913398458,\n",
       " -20675.975241617307,\n",
       " -20670.57987575664,\n",
       " -20665.212809845343,\n",
       " -20659.873819774657,\n",
       " -20654.562683850792,\n",
       " -20649.279182762]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_history_0_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yyatsiuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  if __name__ == '__main__':\n",
      "/Users/yyatsiuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3243eb694252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run with L2 = 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlog_reg_l2_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcoefficients_4_penalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_history_4_penalty\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mlog_reg_l2_4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-c6f1909c1554>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mpenalty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mlogloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_function_with_l2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run with L2 = 4\n",
    "log_reg_l2_4 = LogisticRegression(l2=4, step_size=5e-6, n_rounds=300)\n",
    "coefficients_4_penalty, cost_history_4_penalty  = log_reg_l2_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_history_4_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
